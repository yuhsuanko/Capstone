{
  "best_global_step": 2200,
  "best_metric": 0.6599389314651489,
  "best_model_checkpoint": "/content/drive/MyDrive/Work/Capstone-TeamFolder/Fine-Tuning/FineTune_Apollo7B/Model_Output/checkpoint-2200",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 2200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.045454545454545456,
      "grad_norm": 148.73056030273438,
      "learning_rate": 1.8181818181818183e-07,
      "loss": 1.8911,
      "step": 10
    },
    {
      "epoch": 0.09090909090909091,
      "grad_norm": 151.61880493164062,
      "learning_rate": 6.363636363636364e-07,
      "loss": 2.348,
      "step": 20
    },
    {
      "epoch": 0.13636363636363635,
      "grad_norm": 58.3046760559082,
      "learning_rate": 1.090909090909091e-06,
      "loss": 2.0959,
      "step": 30
    },
    {
      "epoch": 0.18181818181818182,
      "grad_norm": 88.03495788574219,
      "learning_rate": 1.5454545454545454e-06,
      "loss": 1.7958,
      "step": 40
    },
    {
      "epoch": 0.22727272727272727,
      "grad_norm": 182.87432861328125,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 2.254,
      "step": 50
    },
    {
      "epoch": 0.2727272727272727,
      "grad_norm": 210.2073516845703,
      "learning_rate": 2.454545454545455e-06,
      "loss": 2.1705,
      "step": 60
    },
    {
      "epoch": 0.3181818181818182,
      "grad_norm": 203.06536865234375,
      "learning_rate": 2.9090909090909093e-06,
      "loss": 2.3088,
      "step": 70
    },
    {
      "epoch": 0.36363636363636365,
      "grad_norm": 192.93643188476562,
      "learning_rate": 3.3636363636363637e-06,
      "loss": 2.2307,
      "step": 80
    },
    {
      "epoch": 0.4090909090909091,
      "grad_norm": 175.38858032226562,
      "learning_rate": 3.818181818181819e-06,
      "loss": 1.9366,
      "step": 90
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 115.79377746582031,
      "learning_rate": 4.272727272727273e-06,
      "loss": 1.9259,
      "step": 100
    },
    {
      "epoch": 0.5,
      "grad_norm": 249.936279296875,
      "learning_rate": 4.727272727272728e-06,
      "loss": 1.7982,
      "step": 110
    },
    {
      "epoch": 0.5454545454545454,
      "grad_norm": 63.89433670043945,
      "learning_rate": 5.181818181818182e-06,
      "loss": 1.3052,
      "step": 120
    },
    {
      "epoch": 0.5909090909090909,
      "grad_norm": 152.9989776611328,
      "learning_rate": 5.636363636363636e-06,
      "loss": 0.9047,
      "step": 130
    },
    {
      "epoch": 0.6363636363636364,
      "grad_norm": 175.40676879882812,
      "learning_rate": 6.090909090909092e-06,
      "loss": 1.1714,
      "step": 140
    },
    {
      "epoch": 0.6818181818181818,
      "grad_norm": 79.67340850830078,
      "learning_rate": 6.545454545454546e-06,
      "loss": 1.0653,
      "step": 150
    },
    {
      "epoch": 0.7272727272727273,
      "grad_norm": 23.152109146118164,
      "learning_rate": 7e-06,
      "loss": 0.8737,
      "step": 160
    },
    {
      "epoch": 0.7727272727272727,
      "grad_norm": 28.204608917236328,
      "learning_rate": 7.454545454545456e-06,
      "loss": 0.8368,
      "step": 170
    },
    {
      "epoch": 0.8181818181818182,
      "grad_norm": 100.72608947753906,
      "learning_rate": 7.909090909090909e-06,
      "loss": 0.8225,
      "step": 180
    },
    {
      "epoch": 0.8636363636363636,
      "grad_norm": 154.46397399902344,
      "learning_rate": 8.363636363636365e-06,
      "loss": 0.8668,
      "step": 190
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 72.8710708618164,
      "learning_rate": 8.818181818181819e-06,
      "loss": 0.8518,
      "step": 200
    },
    {
      "epoch": 0.9545454545454546,
      "grad_norm": 27.780698776245117,
      "learning_rate": 9.272727272727273e-06,
      "loss": 0.9062,
      "step": 210
    },
    {
      "epoch": 1.0,
      "grad_norm": 113.11071014404297,
      "learning_rate": 9.727272727272728e-06,
      "loss": 0.73,
      "step": 220
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.615909090909091,
      "eval_auc": 0.5137166848561836,
      "eval_f1": 0.20657276995305165,
      "eval_false_negatives": 235,
      "eval_false_positives": 103,
      "eval_loss": 0.7795461416244507,
      "eval_precision": 0.29931972789115646,
      "eval_recall/sensitivity": 0.15770609318996415,
      "eval_runtime": 15.5289,
      "eval_samples_per_second": 56.669,
      "eval_specificity": 0.8286189683860233,
      "eval_steps_per_second": 7.084,
      "eval_true_negatives": 498,
      "eval_true_positives": 44,
      "step": 220
    },
    {
      "epoch": 1.0454545454545454,
      "grad_norm": 33.34233856201172,
      "learning_rate": 9.97979797979798e-06,
      "loss": 0.799,
      "step": 230
    },
    {
      "epoch": 1.0909090909090908,
      "grad_norm": 30.11237144470215,
      "learning_rate": 9.92929292929293e-06,
      "loss": 0.8845,
      "step": 240
    },
    {
      "epoch": 1.1363636363636362,
      "grad_norm": 10.565031051635742,
      "learning_rate": 9.87878787878788e-06,
      "loss": 0.7275,
      "step": 250
    },
    {
      "epoch": 1.1818181818181819,
      "grad_norm": 13.837212562561035,
      "learning_rate": 9.828282828282829e-06,
      "loss": 0.8819,
      "step": 260
    },
    {
      "epoch": 1.2272727272727273,
      "grad_norm": 33.89454650878906,
      "learning_rate": 9.777777777777779e-06,
      "loss": 0.8361,
      "step": 270
    },
    {
      "epoch": 1.2727272727272727,
      "grad_norm": 54.882469177246094,
      "learning_rate": 9.727272727272728e-06,
      "loss": 0.656,
      "step": 280
    },
    {
      "epoch": 1.3181818181818181,
      "grad_norm": 74.17539978027344,
      "learning_rate": 9.676767676767678e-06,
      "loss": 0.7386,
      "step": 290
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 83.86079406738281,
      "learning_rate": 9.626262626262626e-06,
      "loss": 0.8507,
      "step": 300
    },
    {
      "epoch": 1.4090909090909092,
      "grad_norm": 73.02407836914062,
      "learning_rate": 9.575757575757576e-06,
      "loss": 0.7664,
      "step": 310
    },
    {
      "epoch": 1.4545454545454546,
      "grad_norm": 111.73259735107422,
      "learning_rate": 9.525252525252526e-06,
      "loss": 0.7394,
      "step": 320
    },
    {
      "epoch": 1.5,
      "grad_norm": 26.907512664794922,
      "learning_rate": 9.474747474747475e-06,
      "loss": 0.696,
      "step": 330
    },
    {
      "epoch": 1.5454545454545454,
      "grad_norm": 20.12360954284668,
      "learning_rate": 9.424242424242425e-06,
      "loss": 0.6968,
      "step": 340
    },
    {
      "epoch": 1.5909090909090908,
      "grad_norm": 48.24897384643555,
      "learning_rate": 9.373737373737375e-06,
      "loss": 0.6463,
      "step": 350
    },
    {
      "epoch": 1.6363636363636362,
      "grad_norm": 84.9698257446289,
      "learning_rate": 9.323232323232325e-06,
      "loss": 0.9001,
      "step": 360
    },
    {
      "epoch": 1.6818181818181817,
      "grad_norm": 100.41346740722656,
      "learning_rate": 9.272727272727273e-06,
      "loss": 0.7161,
      "step": 370
    },
    {
      "epoch": 1.7272727272727273,
      "grad_norm": 49.65080261230469,
      "learning_rate": 9.222222222222224e-06,
      "loss": 0.6671,
      "step": 380
    },
    {
      "epoch": 1.7727272727272727,
      "grad_norm": 13.040837287902832,
      "learning_rate": 9.171717171717172e-06,
      "loss": 0.779,
      "step": 390
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 49.082176208496094,
      "learning_rate": 9.121212121212122e-06,
      "loss": 0.7525,
      "step": 400
    },
    {
      "epoch": 1.8636363636363638,
      "grad_norm": 90.42325592041016,
      "learning_rate": 9.070707070707072e-06,
      "loss": 0.7334,
      "step": 410
    },
    {
      "epoch": 1.9090909090909092,
      "grad_norm": 43.60327911376953,
      "learning_rate": 9.020202020202021e-06,
      "loss": 0.8313,
      "step": 420
    },
    {
      "epoch": 1.9545454545454546,
      "grad_norm": 18.296489715576172,
      "learning_rate": 8.969696969696971e-06,
      "loss": 0.7312,
      "step": 430
    },
    {
      "epoch": 2.0,
      "grad_norm": 70.59404754638672,
      "learning_rate": 8.919191919191919e-06,
      "loss": 0.7467,
      "step": 440
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.625,
      "eval_auc": 0.5077022167355483,
      "eval_f1": 0.22897196261682243,
      "eval_false_negatives": 230,
      "eval_false_positives": 100,
      "eval_loss": 0.706563413143158,
      "eval_precision": 0.3288590604026846,
      "eval_recall/sensitivity": 0.17562724014336917,
      "eval_runtime": 15.5372,
      "eval_samples_per_second": 56.638,
      "eval_specificity": 0.8336106489184693,
      "eval_steps_per_second": 7.08,
      "eval_true_negatives": 501,
      "eval_true_positives": 49,
      "step": 440
    },
    {
      "epoch": 2.0454545454545454,
      "grad_norm": 33.40233612060547,
      "learning_rate": 8.86868686868687e-06,
      "loss": 0.6956,
      "step": 450
    },
    {
      "epoch": 2.090909090909091,
      "grad_norm": 33.53640365600586,
      "learning_rate": 8.818181818181819e-06,
      "loss": 0.73,
      "step": 460
    },
    {
      "epoch": 2.1363636363636362,
      "grad_norm": 67.86771392822266,
      "learning_rate": 8.767676767676768e-06,
      "loss": 0.7194,
      "step": 470
    },
    {
      "epoch": 2.1818181818181817,
      "grad_norm": 34.39822006225586,
      "learning_rate": 8.717171717171718e-06,
      "loss": 0.7134,
      "step": 480
    },
    {
      "epoch": 2.227272727272727,
      "grad_norm": 22.10993194580078,
      "learning_rate": 8.666666666666668e-06,
      "loss": 0.7275,
      "step": 490
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 19.975862503051758,
      "learning_rate": 8.616161616161618e-06,
      "loss": 0.6846,
      "step": 500
    },
    {
      "epoch": 2.3181818181818183,
      "grad_norm": 10.63027572631836,
      "learning_rate": 8.565656565656566e-06,
      "loss": 0.7085,
      "step": 510
    },
    {
      "epoch": 2.3636363636363638,
      "grad_norm": 91.26294708251953,
      "learning_rate": 8.515151515151517e-06,
      "loss": 0.6689,
      "step": 520
    },
    {
      "epoch": 2.409090909090909,
      "grad_norm": 15.224055290222168,
      "learning_rate": 8.464646464646465e-06,
      "loss": 0.7138,
      "step": 530
    },
    {
      "epoch": 2.4545454545454546,
      "grad_norm": 49.010284423828125,
      "learning_rate": 8.414141414141415e-06,
      "loss": 0.7047,
      "step": 540
    },
    {
      "epoch": 2.5,
      "grad_norm": 30.707134246826172,
      "learning_rate": 8.363636363636365e-06,
      "loss": 0.6977,
      "step": 550
    },
    {
      "epoch": 2.5454545454545454,
      "grad_norm": 8.38454818725586,
      "learning_rate": 8.313131313131314e-06,
      "loss": 0.7317,
      "step": 560
    },
    {
      "epoch": 2.590909090909091,
      "grad_norm": 60.553733825683594,
      "learning_rate": 8.262626262626264e-06,
      "loss": 0.6313,
      "step": 570
    },
    {
      "epoch": 2.6363636363636362,
      "grad_norm": 26.218854904174805,
      "learning_rate": 8.212121212121212e-06,
      "loss": 0.77,
      "step": 580
    },
    {
      "epoch": 2.6818181818181817,
      "grad_norm": 32.775596618652344,
      "learning_rate": 8.161616161616162e-06,
      "loss": 0.8312,
      "step": 590
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 79.8745346069336,
      "learning_rate": 8.111111111111112e-06,
      "loss": 0.7326,
      "step": 600
    },
    {
      "epoch": 2.7727272727272725,
      "grad_norm": 14.901695251464844,
      "learning_rate": 8.060606060606061e-06,
      "loss": 0.7138,
      "step": 610
    },
    {
      "epoch": 2.8181818181818183,
      "grad_norm": 76.0438232421875,
      "learning_rate": 8.010101010101011e-06,
      "loss": 0.6309,
      "step": 620
    },
    {
      "epoch": 2.8636363636363638,
      "grad_norm": 19.81575584411621,
      "learning_rate": 7.95959595959596e-06,
      "loss": 0.731,
      "step": 630
    },
    {
      "epoch": 2.909090909090909,
      "grad_norm": 23.985498428344727,
      "learning_rate": 7.909090909090909e-06,
      "loss": 0.704,
      "step": 640
    },
    {
      "epoch": 2.9545454545454546,
      "grad_norm": 8.109000205993652,
      "learning_rate": 7.858585858585859e-06,
      "loss": 0.6859,
      "step": 650
    },
    {
      "epoch": 3.0,
      "grad_norm": 19.718242645263672,
      "learning_rate": 7.808080808080808e-06,
      "loss": 0.7251,
      "step": 660
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.6386363636363637,
      "eval_auc": 0.5087071129956644,
      "eval_f1": 0.23557692307692307,
      "eval_false_negatives": 230,
      "eval_false_positives": 88,
      "eval_loss": 0.6874388456344604,
      "eval_precision": 0.35766423357664234,
      "eval_recall/sensitivity": 0.17562724014336917,
      "eval_runtime": 15.5385,
      "eval_samples_per_second": 56.634,
      "eval_specificity": 0.8535773710482529,
      "eval_steps_per_second": 7.079,
      "eval_true_negatives": 513,
      "eval_true_positives": 49,
      "step": 660
    },
    {
      "epoch": 3.0454545454545454,
      "grad_norm": 75.55381774902344,
      "learning_rate": 7.757575757575758e-06,
      "loss": 0.6997,
      "step": 670
    },
    {
      "epoch": 3.090909090909091,
      "grad_norm": 62.34236145019531,
      "learning_rate": 7.707070707070708e-06,
      "loss": 0.7103,
      "step": 680
    },
    {
      "epoch": 3.1363636363636362,
      "grad_norm": 52.60212326049805,
      "learning_rate": 7.656565656565658e-06,
      "loss": 0.7066,
      "step": 690
    },
    {
      "epoch": 3.1818181818181817,
      "grad_norm": 53.0551872253418,
      "learning_rate": 7.606060606060606e-06,
      "loss": 0.6726,
      "step": 700
    },
    {
      "epoch": 3.227272727272727,
      "grad_norm": 92.7587890625,
      "learning_rate": 7.555555555555556e-06,
      "loss": 0.7599,
      "step": 710
    },
    {
      "epoch": 3.2727272727272725,
      "grad_norm": 9.506401062011719,
      "learning_rate": 7.505050505050505e-06,
      "loss": 0.7235,
      "step": 720
    },
    {
      "epoch": 3.3181818181818183,
      "grad_norm": 105.96760559082031,
      "learning_rate": 7.454545454545456e-06,
      "loss": 0.7054,
      "step": 730
    },
    {
      "epoch": 3.3636363636363638,
      "grad_norm": 24.464923858642578,
      "learning_rate": 7.4040404040404045e-06,
      "loss": 0.653,
      "step": 740
    },
    {
      "epoch": 3.409090909090909,
      "grad_norm": 76.41704559326172,
      "learning_rate": 7.353535353535353e-06,
      "loss": 0.7504,
      "step": 750
    },
    {
      "epoch": 3.4545454545454546,
      "grad_norm": 20.41671371459961,
      "learning_rate": 7.303030303030304e-06,
      "loss": 0.7158,
      "step": 760
    },
    {
      "epoch": 3.5,
      "grad_norm": 28.13232421875,
      "learning_rate": 7.252525252525253e-06,
      "loss": 0.7373,
      "step": 770
    },
    {
      "epoch": 3.5454545454545454,
      "grad_norm": 16.504030227661133,
      "learning_rate": 7.202020202020203e-06,
      "loss": 0.6525,
      "step": 780
    },
    {
      "epoch": 3.590909090909091,
      "grad_norm": 12.645970344543457,
      "learning_rate": 7.151515151515152e-06,
      "loss": 0.5758,
      "step": 790
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 14.067538261413574,
      "learning_rate": 7.101010101010102e-06,
      "loss": 0.646,
      "step": 800
    },
    {
      "epoch": 3.6818181818181817,
      "grad_norm": 20.41844367980957,
      "learning_rate": 7.050505050505051e-06,
      "loss": 0.7152,
      "step": 810
    },
    {
      "epoch": 3.7272727272727275,
      "grad_norm": 24.838130950927734,
      "learning_rate": 7e-06,
      "loss": 0.6461,
      "step": 820
    },
    {
      "epoch": 3.7727272727272725,
      "grad_norm": 13.802802085876465,
      "learning_rate": 6.9494949494949505e-06,
      "loss": 0.7743,
      "step": 830
    },
    {
      "epoch": 3.8181818181818183,
      "grad_norm": 51.332611083984375,
      "learning_rate": 6.898989898989899e-06,
      "loss": 0.6211,
      "step": 840
    },
    {
      "epoch": 3.8636363636363638,
      "grad_norm": 29.390979766845703,
      "learning_rate": 6.848484848484849e-06,
      "loss": 0.7105,
      "step": 850
    },
    {
      "epoch": 3.909090909090909,
      "grad_norm": 75.18765258789062,
      "learning_rate": 6.797979797979799e-06,
      "loss": 0.7613,
      "step": 860
    },
    {
      "epoch": 3.9545454545454546,
      "grad_norm": 22.604026794433594,
      "learning_rate": 6.747474747474749e-06,
      "loss": 0.6081,
      "step": 870
    },
    {
      "epoch": 4.0,
      "grad_norm": 53.02461624145508,
      "learning_rate": 6.6969696969696975e-06,
      "loss": 0.5867,
      "step": 880
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.6647727272727273,
      "eval_auc": 0.5143667364428461,
      "eval_f1": 0.09785932721712538,
      "eval_false_negatives": 263,
      "eval_false_positives": 32,
      "eval_loss": 0.683324933052063,
      "eval_precision": 0.3333333333333333,
      "eval_recall/sensitivity": 0.05734767025089606,
      "eval_runtime": 15.5715,
      "eval_samples_per_second": 56.514,
      "eval_specificity": 0.9467554076539102,
      "eval_steps_per_second": 7.064,
      "eval_true_negatives": 569,
      "eval_true_positives": 16,
      "step": 880
    },
    {
      "epoch": 4.045454545454546,
      "grad_norm": 14.197688102722168,
      "learning_rate": 6.646464646464646e-06,
      "loss": 0.7254,
      "step": 890
    },
    {
      "epoch": 4.090909090909091,
      "grad_norm": 40.811100006103516,
      "learning_rate": 6.595959595959597e-06,
      "loss": 0.6996,
      "step": 900
    },
    {
      "epoch": 4.136363636363637,
      "grad_norm": 77.1686782836914,
      "learning_rate": 6.545454545454546e-06,
      "loss": 0.7103,
      "step": 910
    },
    {
      "epoch": 4.181818181818182,
      "grad_norm": 32.25864791870117,
      "learning_rate": 6.494949494949495e-06,
      "loss": 0.6261,
      "step": 920
    },
    {
      "epoch": 4.2272727272727275,
      "grad_norm": 30.938312530517578,
      "learning_rate": 6.444444444444445e-06,
      "loss": 0.6176,
      "step": 930
    },
    {
      "epoch": 4.2727272727272725,
      "grad_norm": 34.02070999145508,
      "learning_rate": 6.393939393939394e-06,
      "loss": 0.6041,
      "step": 940
    },
    {
      "epoch": 4.318181818181818,
      "grad_norm": 27.96192169189453,
      "learning_rate": 6.343434343434344e-06,
      "loss": 0.663,
      "step": 950
    },
    {
      "epoch": 4.363636363636363,
      "grad_norm": 126.81099700927734,
      "learning_rate": 6.292929292929294e-06,
      "loss": 0.6596,
      "step": 960
    },
    {
      "epoch": 4.409090909090909,
      "grad_norm": 11.232438087463379,
      "learning_rate": 6.2424242424242434e-06,
      "loss": 0.679,
      "step": 970
    },
    {
      "epoch": 4.454545454545454,
      "grad_norm": 55.141666412353516,
      "learning_rate": 6.191919191919192e-06,
      "loss": 0.6815,
      "step": 980
    },
    {
      "epoch": 4.5,
      "grad_norm": 21.300491333007812,
      "learning_rate": 6.141414141414141e-06,
      "loss": 0.6552,
      "step": 990
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 50.35832214355469,
      "learning_rate": 6.090909090909092e-06,
      "loss": 0.698,
      "step": 1000
    },
    {
      "epoch": 4.590909090909091,
      "grad_norm": 80.10535430908203,
      "learning_rate": 6.040404040404041e-06,
      "loss": 0.6241,
      "step": 1010
    },
    {
      "epoch": 4.636363636363637,
      "grad_norm": 10.448628425598145,
      "learning_rate": 5.9898989898989904e-06,
      "loss": 0.6847,
      "step": 1020
    },
    {
      "epoch": 4.681818181818182,
      "grad_norm": 20.073427200317383,
      "learning_rate": 5.93939393939394e-06,
      "loss": 0.699,
      "step": 1030
    },
    {
      "epoch": 4.7272727272727275,
      "grad_norm": 21.87322235107422,
      "learning_rate": 5.88888888888889e-06,
      "loss": 0.7167,
      "step": 1040
    },
    {
      "epoch": 4.7727272727272725,
      "grad_norm": 72.10717010498047,
      "learning_rate": 5.838383838383839e-06,
      "loss": 0.7603,
      "step": 1050
    },
    {
      "epoch": 4.818181818181818,
      "grad_norm": 12.135974884033203,
      "learning_rate": 5.787878787878788e-06,
      "loss": 0.6356,
      "step": 1060
    },
    {
      "epoch": 4.863636363636363,
      "grad_norm": 36.98219299316406,
      "learning_rate": 5.737373737373738e-06,
      "loss": 0.7014,
      "step": 1070
    },
    {
      "epoch": 4.909090909090909,
      "grad_norm": 99.44453430175781,
      "learning_rate": 5.686868686868687e-06,
      "loss": 0.7236,
      "step": 1080
    },
    {
      "epoch": 4.954545454545455,
      "grad_norm": 67.34162902832031,
      "learning_rate": 5.636363636363636e-06,
      "loss": 0.6581,
      "step": 1090
    },
    {
      "epoch": 5.0,
      "grad_norm": 12.451932907104492,
      "learning_rate": 5.585858585858587e-06,
      "loss": 0.6704,
      "step": 1100
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.6613636363636364,
      "eval_auc": 0.5203245486912493,
      "eval_f1": 0.1534090909090909,
      "eval_false_negatives": 252,
      "eval_false_positives": 46,
      "eval_loss": 0.6694004535675049,
      "eval_precision": 0.3698630136986301,
      "eval_recall/sensitivity": 0.0967741935483871,
      "eval_runtime": 15.5084,
      "eval_samples_per_second": 56.743,
      "eval_specificity": 0.9234608985024958,
      "eval_steps_per_second": 7.093,
      "eval_true_negatives": 555,
      "eval_true_positives": 27,
      "step": 1100
    },
    {
      "epoch": 5.045454545454546,
      "grad_norm": 23.636484146118164,
      "learning_rate": 5.5353535353535355e-06,
      "loss": 0.6463,
      "step": 1110
    },
    {
      "epoch": 5.090909090909091,
      "grad_norm": 20.95290184020996,
      "learning_rate": 5.484848484848485e-06,
      "loss": 0.7589,
      "step": 1120
    },
    {
      "epoch": 5.136363636363637,
      "grad_norm": 43.34003829956055,
      "learning_rate": 5.434343434343434e-06,
      "loss": 0.6621,
      "step": 1130
    },
    {
      "epoch": 5.181818181818182,
      "grad_norm": 16.348304748535156,
      "learning_rate": 5.383838383838385e-06,
      "loss": 0.6972,
      "step": 1140
    },
    {
      "epoch": 5.2272727272727275,
      "grad_norm": 11.869916915893555,
      "learning_rate": 5.333333333333334e-06,
      "loss": 0.7192,
      "step": 1150
    },
    {
      "epoch": 5.2727272727272725,
      "grad_norm": 20.273311614990234,
      "learning_rate": 5.2828282828282825e-06,
      "loss": 0.6144,
      "step": 1160
    },
    {
      "epoch": 5.318181818181818,
      "grad_norm": 17.026302337646484,
      "learning_rate": 5.232323232323233e-06,
      "loss": 0.5888,
      "step": 1170
    },
    {
      "epoch": 5.363636363636363,
      "grad_norm": 52.17823791503906,
      "learning_rate": 5.181818181818182e-06,
      "loss": 0.6404,
      "step": 1180
    },
    {
      "epoch": 5.409090909090909,
      "grad_norm": 76.50878143310547,
      "learning_rate": 5.131313131313132e-06,
      "loss": 0.7007,
      "step": 1190
    },
    {
      "epoch": 5.454545454545454,
      "grad_norm": 29.476911544799805,
      "learning_rate": 5.0808080808080815e-06,
      "loss": 0.7243,
      "step": 1200
    },
    {
      "epoch": 5.5,
      "grad_norm": 122.02527618408203,
      "learning_rate": 5.030303030303031e-06,
      "loss": 0.6405,
      "step": 1210
    },
    {
      "epoch": 5.545454545454545,
      "grad_norm": 46.532379150390625,
      "learning_rate": 4.97979797979798e-06,
      "loss": 0.7353,
      "step": 1220
    },
    {
      "epoch": 5.590909090909091,
      "grad_norm": 73.73363494873047,
      "learning_rate": 4.92929292929293e-06,
      "loss": 0.6504,
      "step": 1230
    },
    {
      "epoch": 5.636363636363637,
      "grad_norm": 19.060495376586914,
      "learning_rate": 4.878787878787879e-06,
      "loss": 0.7683,
      "step": 1240
    },
    {
      "epoch": 5.681818181818182,
      "grad_norm": 38.675296783447266,
      "learning_rate": 4.8282828282828285e-06,
      "loss": 0.6289,
      "step": 1250
    },
    {
      "epoch": 5.7272727272727275,
      "grad_norm": 40.95538330078125,
      "learning_rate": 4.777777777777778e-06,
      "loss": 0.6499,
      "step": 1260
    },
    {
      "epoch": 5.7727272727272725,
      "grad_norm": 55.32521057128906,
      "learning_rate": 4.727272727272728e-06,
      "loss": 0.6276,
      "step": 1270
    },
    {
      "epoch": 5.818181818181818,
      "grad_norm": 32.41248321533203,
      "learning_rate": 4.676767676767677e-06,
      "loss": 0.7101,
      "step": 1280
    },
    {
      "epoch": 5.863636363636363,
      "grad_norm": 46.85200119018555,
      "learning_rate": 4.626262626262627e-06,
      "loss": 0.7118,
      "step": 1290
    },
    {
      "epoch": 5.909090909090909,
      "grad_norm": 23.174846649169922,
      "learning_rate": 4.575757575757576e-06,
      "loss": 0.6159,
      "step": 1300
    },
    {
      "epoch": 5.954545454545455,
      "grad_norm": 71.30475616455078,
      "learning_rate": 4.525252525252526e-06,
      "loss": 0.5819,
      "step": 1310
    },
    {
      "epoch": 6.0,
      "grad_norm": 99.84892272949219,
      "learning_rate": 4.474747474747475e-06,
      "loss": 0.6909,
      "step": 1320
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.6670454545454545,
      "eval_auc": 0.527179909231329,
      "eval_f1": 0.1148036253776435,
      "eval_false_negatives": 260,
      "eval_false_positives": 33,
      "eval_loss": 0.6687486171722412,
      "eval_precision": 0.36538461538461536,
      "eval_recall/sensitivity": 0.06810035842293907,
      "eval_runtime": 15.5363,
      "eval_samples_per_second": 56.642,
      "eval_specificity": 0.9450915141430949,
      "eval_steps_per_second": 7.08,
      "eval_true_negatives": 568,
      "eval_true_positives": 19,
      "step": 1320
    },
    {
      "epoch": 6.045454545454546,
      "grad_norm": 28.169029235839844,
      "learning_rate": 4.424242424242425e-06,
      "loss": 0.6626,
      "step": 1330
    },
    {
      "epoch": 6.090909090909091,
      "grad_norm": 43.043643951416016,
      "learning_rate": 4.373737373737374e-06,
      "loss": 0.7074,
      "step": 1340
    },
    {
      "epoch": 6.136363636363637,
      "grad_norm": 69.42986297607422,
      "learning_rate": 4.323232323232323e-06,
      "loss": 0.5888,
      "step": 1350
    },
    {
      "epoch": 6.181818181818182,
      "grad_norm": 61.231468200683594,
      "learning_rate": 4.272727272727273e-06,
      "loss": 0.7341,
      "step": 1360
    },
    {
      "epoch": 6.2272727272727275,
      "grad_norm": 16.697444915771484,
      "learning_rate": 4.222222222222223e-06,
      "loss": 0.5942,
      "step": 1370
    },
    {
      "epoch": 6.2727272727272725,
      "grad_norm": 119.81755065917969,
      "learning_rate": 4.1717171717171726e-06,
      "loss": 0.664,
      "step": 1380
    },
    {
      "epoch": 6.318181818181818,
      "grad_norm": 19.674442291259766,
      "learning_rate": 4.1212121212121215e-06,
      "loss": 0.5907,
      "step": 1390
    },
    {
      "epoch": 6.363636363636363,
      "grad_norm": 13.30229377746582,
      "learning_rate": 4.070707070707071e-06,
      "loss": 0.6329,
      "step": 1400
    },
    {
      "epoch": 6.409090909090909,
      "grad_norm": 71.93905639648438,
      "learning_rate": 4.02020202020202e-06,
      "loss": 0.7003,
      "step": 1410
    },
    {
      "epoch": 6.454545454545454,
      "grad_norm": 82.44358825683594,
      "learning_rate": 3.96969696969697e-06,
      "loss": 0.5776,
      "step": 1420
    },
    {
      "epoch": 6.5,
      "grad_norm": 22.136859893798828,
      "learning_rate": 3.9191919191919196e-06,
      "loss": 0.6825,
      "step": 1430
    },
    {
      "epoch": 6.545454545454545,
      "grad_norm": 9.672290802001953,
      "learning_rate": 3.868686868686869e-06,
      "loss": 0.6522,
      "step": 1440
    },
    {
      "epoch": 6.590909090909091,
      "grad_norm": 63.41587448120117,
      "learning_rate": 3.818181818181819e-06,
      "loss": 0.7613,
      "step": 1450
    },
    {
      "epoch": 6.636363636363637,
      "grad_norm": 45.362548828125,
      "learning_rate": 3.767676767676768e-06,
      "loss": 0.7085,
      "step": 1460
    },
    {
      "epoch": 6.681818181818182,
      "grad_norm": 59.648902893066406,
      "learning_rate": 3.7171717171717177e-06,
      "loss": 0.6347,
      "step": 1470
    },
    {
      "epoch": 6.7272727272727275,
      "grad_norm": 47.312339782714844,
      "learning_rate": 3.6666666666666666e-06,
      "loss": 0.7154,
      "step": 1480
    },
    {
      "epoch": 6.7727272727272725,
      "grad_norm": 23.71395492553711,
      "learning_rate": 3.6161616161616163e-06,
      "loss": 0.6355,
      "step": 1490
    },
    {
      "epoch": 6.818181818181818,
      "grad_norm": 8.769472122192383,
      "learning_rate": 3.565656565656566e-06,
      "loss": 0.6533,
      "step": 1500
    },
    {
      "epoch": 6.863636363636363,
      "grad_norm": 30.959484100341797,
      "learning_rate": 3.5151515151515154e-06,
      "loss": 0.6907,
      "step": 1510
    },
    {
      "epoch": 6.909090909090909,
      "grad_norm": 57.066646575927734,
      "learning_rate": 3.464646464646465e-06,
      "loss": 0.6624,
      "step": 1520
    },
    {
      "epoch": 6.954545454545455,
      "grad_norm": 37.040985107421875,
      "learning_rate": 3.414141414141414e-06,
      "loss": 0.6021,
      "step": 1530
    },
    {
      "epoch": 7.0,
      "grad_norm": 13.878729820251465,
      "learning_rate": 3.3636363636363637e-06,
      "loss": 0.7728,
      "step": 1540
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.6625,
      "eval_auc": 0.5311637116156466,
      "eval_f1": 0.12903225806451613,
      "eval_false_negatives": 257,
      "eval_false_positives": 40,
      "eval_loss": 0.6631859540939331,
      "eval_precision": 0.3548387096774194,
      "eval_recall/sensitivity": 0.07885304659498207,
      "eval_runtime": 15.5369,
      "eval_samples_per_second": 56.639,
      "eval_specificity": 0.9334442595673876,
      "eval_steps_per_second": 7.08,
      "eval_true_negatives": 561,
      "eval_true_positives": 22,
      "step": 1540
    },
    {
      "epoch": 7.045454545454546,
      "grad_norm": 102.7198486328125,
      "learning_rate": 3.3131313131313135e-06,
      "loss": 0.6624,
      "step": 1550
    },
    {
      "epoch": 7.090909090909091,
      "grad_norm": 42.711456298828125,
      "learning_rate": 3.262626262626263e-06,
      "loss": 0.6386,
      "step": 1560
    },
    {
      "epoch": 7.136363636363637,
      "grad_norm": 21.258567810058594,
      "learning_rate": 3.2121212121212125e-06,
      "loss": 0.7059,
      "step": 1570
    },
    {
      "epoch": 7.181818181818182,
      "grad_norm": 63.290985107421875,
      "learning_rate": 3.161616161616162e-06,
      "loss": 0.6111,
      "step": 1580
    },
    {
      "epoch": 7.2272727272727275,
      "grad_norm": 33.87998580932617,
      "learning_rate": 3.1111111111111116e-06,
      "loss": 0.6949,
      "step": 1590
    },
    {
      "epoch": 7.2727272727272725,
      "grad_norm": 54.37482452392578,
      "learning_rate": 3.0606060606060605e-06,
      "loss": 0.6391,
      "step": 1600
    },
    {
      "epoch": 7.318181818181818,
      "grad_norm": 60.364723205566406,
      "learning_rate": 3.0101010101010102e-06,
      "loss": 0.6021,
      "step": 1610
    },
    {
      "epoch": 7.363636363636363,
      "grad_norm": 56.21725082397461,
      "learning_rate": 2.95959595959596e-06,
      "loss": 0.5934,
      "step": 1620
    },
    {
      "epoch": 7.409090909090909,
      "grad_norm": 51.08549499511719,
      "learning_rate": 2.9090909090909093e-06,
      "loss": 0.7292,
      "step": 1630
    },
    {
      "epoch": 7.454545454545454,
      "grad_norm": 82.69536590576172,
      "learning_rate": 2.858585858585859e-06,
      "loss": 0.7059,
      "step": 1640
    },
    {
      "epoch": 7.5,
      "grad_norm": 31.938800811767578,
      "learning_rate": 2.808080808080808e-06,
      "loss": 0.6588,
      "step": 1650
    },
    {
      "epoch": 7.545454545454545,
      "grad_norm": 109.25430297851562,
      "learning_rate": 2.7575757575757576e-06,
      "loss": 0.7086,
      "step": 1660
    },
    {
      "epoch": 7.590909090909091,
      "grad_norm": 37.1526985168457,
      "learning_rate": 2.7070707070707074e-06,
      "loss": 0.6187,
      "step": 1670
    },
    {
      "epoch": 7.636363636363637,
      "grad_norm": 19.22244644165039,
      "learning_rate": 2.6565656565656567e-06,
      "loss": 0.5404,
      "step": 1680
    },
    {
      "epoch": 7.681818181818182,
      "grad_norm": 26.861635208129883,
      "learning_rate": 2.6060606060606064e-06,
      "loss": 0.6775,
      "step": 1690
    },
    {
      "epoch": 7.7272727272727275,
      "grad_norm": 25.956527709960938,
      "learning_rate": 2.5555555555555557e-06,
      "loss": 0.6856,
      "step": 1700
    },
    {
      "epoch": 7.7727272727272725,
      "grad_norm": 93.8487777709961,
      "learning_rate": 2.5050505050505055e-06,
      "loss": 0.7214,
      "step": 1710
    },
    {
      "epoch": 7.818181818181818,
      "grad_norm": 24.842947006225586,
      "learning_rate": 2.454545454545455e-06,
      "loss": 0.6613,
      "step": 1720
    },
    {
      "epoch": 7.863636363636363,
      "grad_norm": 28.343257904052734,
      "learning_rate": 2.404040404040404e-06,
      "loss": 0.7027,
      "step": 1730
    },
    {
      "epoch": 7.909090909090909,
      "grad_norm": 113.56202697753906,
      "learning_rate": 2.3535353535353534e-06,
      "loss": 0.6937,
      "step": 1740
    },
    {
      "epoch": 7.954545454545455,
      "grad_norm": 56.870208740234375,
      "learning_rate": 2.303030303030303e-06,
      "loss": 0.6254,
      "step": 1750
    },
    {
      "epoch": 8.0,
      "grad_norm": 142.65126037597656,
      "learning_rate": 2.252525252525253e-06,
      "loss": 0.6766,
      "step": 1760
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.6636363636363637,
      "eval_auc": 0.5336028960096375,
      "eval_f1": 0.17777777777777778,
      "eval_false_negatives": 247,
      "eval_false_positives": 49,
      "eval_loss": 0.6609807014465332,
      "eval_precision": 0.3950617283950617,
      "eval_recall/sensitivity": 0.11469534050179211,
      "eval_runtime": 15.5591,
      "eval_samples_per_second": 56.558,
      "eval_specificity": 0.9184692179700499,
      "eval_steps_per_second": 7.07,
      "eval_true_negatives": 552,
      "eval_true_positives": 32,
      "step": 1760
    },
    {
      "epoch": 8.045454545454545,
      "grad_norm": 15.764974594116211,
      "learning_rate": 2.2020202020202022e-06,
      "loss": 0.7252,
      "step": 1770
    },
    {
      "epoch": 8.090909090909092,
      "grad_norm": 18.634851455688477,
      "learning_rate": 2.1515151515151515e-06,
      "loss": 0.6629,
      "step": 1780
    },
    {
      "epoch": 8.136363636363637,
      "grad_norm": 58.89126968383789,
      "learning_rate": 2.1010101010101013e-06,
      "loss": 0.6324,
      "step": 1790
    },
    {
      "epoch": 8.181818181818182,
      "grad_norm": 38.36491775512695,
      "learning_rate": 2.0505050505050506e-06,
      "loss": 0.6441,
      "step": 1800
    },
    {
      "epoch": 8.227272727272727,
      "grad_norm": 51.80794906616211,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.6407,
      "step": 1810
    },
    {
      "epoch": 8.272727272727273,
      "grad_norm": 33.11334228515625,
      "learning_rate": 1.9494949494949496e-06,
      "loss": 0.7068,
      "step": 1820
    },
    {
      "epoch": 8.318181818181818,
      "grad_norm": 33.56056594848633,
      "learning_rate": 1.8989898989898992e-06,
      "loss": 0.617,
      "step": 1830
    },
    {
      "epoch": 8.363636363636363,
      "grad_norm": 21.470890045166016,
      "learning_rate": 1.8484848484848487e-06,
      "loss": 0.6355,
      "step": 1840
    },
    {
      "epoch": 8.409090909090908,
      "grad_norm": 15.745118141174316,
      "learning_rate": 1.797979797979798e-06,
      "loss": 0.6733,
      "step": 1850
    },
    {
      "epoch": 8.454545454545455,
      "grad_norm": 17.660825729370117,
      "learning_rate": 1.7474747474747475e-06,
      "loss": 0.6256,
      "step": 1860
    },
    {
      "epoch": 8.5,
      "grad_norm": 39.00340270996094,
      "learning_rate": 1.6969696969696973e-06,
      "loss": 0.661,
      "step": 1870
    },
    {
      "epoch": 8.545454545454545,
      "grad_norm": 154.03759765625,
      "learning_rate": 1.6464646464646466e-06,
      "loss": 0.7037,
      "step": 1880
    },
    {
      "epoch": 8.590909090909092,
      "grad_norm": 82.47025299072266,
      "learning_rate": 1.5959595959595961e-06,
      "loss": 0.7135,
      "step": 1890
    },
    {
      "epoch": 8.636363636363637,
      "grad_norm": 58.51512145996094,
      "learning_rate": 1.5454545454545454e-06,
      "loss": 0.6298,
      "step": 1900
    },
    {
      "epoch": 8.681818181818182,
      "grad_norm": 96.17623901367188,
      "learning_rate": 1.494949494949495e-06,
      "loss": 0.6634,
      "step": 1910
    },
    {
      "epoch": 8.727272727272727,
      "grad_norm": 14.275510787963867,
      "learning_rate": 1.4444444444444445e-06,
      "loss": 0.6278,
      "step": 1920
    },
    {
      "epoch": 8.772727272727273,
      "grad_norm": 18.101184844970703,
      "learning_rate": 1.3939393939393942e-06,
      "loss": 0.641,
      "step": 1930
    },
    {
      "epoch": 8.818181818181818,
      "grad_norm": 10.175457000732422,
      "learning_rate": 1.3434343434343436e-06,
      "loss": 0.6063,
      "step": 1940
    },
    {
      "epoch": 8.863636363636363,
      "grad_norm": 30.736825942993164,
      "learning_rate": 1.292929292929293e-06,
      "loss": 0.6323,
      "step": 1950
    },
    {
      "epoch": 8.909090909090908,
      "grad_norm": 56.25973129272461,
      "learning_rate": 1.2424242424242424e-06,
      "loss": 0.7294,
      "step": 1960
    },
    {
      "epoch": 8.954545454545455,
      "grad_norm": 77.22271728515625,
      "learning_rate": 1.1919191919191921e-06,
      "loss": 0.6353,
      "step": 1970
    },
    {
      "epoch": 9.0,
      "grad_norm": 45.444942474365234,
      "learning_rate": 1.1414141414141414e-06,
      "loss": 0.6838,
      "step": 1980
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.6625,
      "eval_auc": 0.536024189075555,
      "eval_f1": 0.1391304347826087,
      "eval_false_negatives": 255,
      "eval_false_positives": 42,
      "eval_loss": 0.6604787707328796,
      "eval_precision": 0.36363636363636365,
      "eval_recall/sensitivity": 0.08602150537634409,
      "eval_runtime": 15.5439,
      "eval_samples_per_second": 56.614,
      "eval_specificity": 0.930116472545757,
      "eval_steps_per_second": 7.077,
      "eval_true_negatives": 559,
      "eval_true_positives": 24,
      "step": 1980
    },
    {
      "epoch": 9.045454545454545,
      "grad_norm": 156.69070434570312,
      "learning_rate": 1.090909090909091e-06,
      "loss": 0.6671,
      "step": 1990
    },
    {
      "epoch": 9.090909090909092,
      "grad_norm": 12.08049201965332,
      "learning_rate": 1.0404040404040405e-06,
      "loss": 0.5689,
      "step": 2000
    },
    {
      "epoch": 9.136363636363637,
      "grad_norm": Infinity,
      "learning_rate": 9.8989898989899e-07,
      "loss": 0.6468,
      "step": 2010
    },
    {
      "epoch": 9.181818181818182,
      "grad_norm": 15.341148376464844,
      "learning_rate": 9.444444444444445e-07,
      "loss": 0.6627,
      "step": 2020
    },
    {
      "epoch": 9.227272727272727,
      "grad_norm": 73.07422637939453,
      "learning_rate": 8.93939393939394e-07,
      "loss": 0.6342,
      "step": 2030
    },
    {
      "epoch": 9.272727272727273,
      "grad_norm": 50.849822998046875,
      "learning_rate": 8.434343434343436e-07,
      "loss": 0.69,
      "step": 2040
    },
    {
      "epoch": 9.318181818181818,
      "grad_norm": 18.7857608795166,
      "learning_rate": 7.92929292929293e-07,
      "loss": 0.7117,
      "step": 2050
    },
    {
      "epoch": 9.363636363636363,
      "grad_norm": 33.085411071777344,
      "learning_rate": 7.424242424242425e-07,
      "loss": 0.7011,
      "step": 2060
    },
    {
      "epoch": 9.409090909090908,
      "grad_norm": 56.86872100830078,
      "learning_rate": 6.919191919191919e-07,
      "loss": 0.675,
      "step": 2070
    },
    {
      "epoch": 9.454545454545455,
      "grad_norm": 11.127731323242188,
      "learning_rate": 6.414141414141415e-07,
      "loss": 0.5749,
      "step": 2080
    },
    {
      "epoch": 9.5,
      "grad_norm": 35.944156646728516,
      "learning_rate": 5.90909090909091e-07,
      "loss": 0.7191,
      "step": 2090
    },
    {
      "epoch": 9.545454545454545,
      "grad_norm": 22.07996368408203,
      "learning_rate": 5.404040404040404e-07,
      "loss": 0.6416,
      "step": 2100
    },
    {
      "epoch": 9.590909090909092,
      "grad_norm": 17.4758243560791,
      "learning_rate": 4.898989898989899e-07,
      "loss": 0.705,
      "step": 2110
    },
    {
      "epoch": 9.636363636363637,
      "grad_norm": 14.480340003967285,
      "learning_rate": 4.393939393939394e-07,
      "loss": 0.6442,
      "step": 2120
    },
    {
      "epoch": 9.681818181818182,
      "grad_norm": 80.79338073730469,
      "learning_rate": 3.8888888888888895e-07,
      "loss": 0.6339,
      "step": 2130
    },
    {
      "epoch": 9.727272727272727,
      "grad_norm": 10.316397666931152,
      "learning_rate": 3.383838383838384e-07,
      "loss": 0.7039,
      "step": 2140
    },
    {
      "epoch": 9.772727272727273,
      "grad_norm": 70.46936798095703,
      "learning_rate": 2.878787878787879e-07,
      "loss": 0.7131,
      "step": 2150
    },
    {
      "epoch": 9.818181818181818,
      "grad_norm": 31.817325592041016,
      "learning_rate": 2.373737373737374e-07,
      "loss": 0.6307,
      "step": 2160
    },
    {
      "epoch": 9.863636363636363,
      "grad_norm": 14.542730331420898,
      "learning_rate": 1.8686868686868687e-07,
      "loss": 0.6183,
      "step": 2170
    },
    {
      "epoch": 9.909090909090908,
      "grad_norm": 73.59011840820312,
      "learning_rate": 1.3636363636363637e-07,
      "loss": 0.7104,
      "step": 2180
    },
    {
      "epoch": 9.954545454545455,
      "grad_norm": 47.956459045410156,
      "learning_rate": 8.585858585858586e-08,
      "loss": 0.6143,
      "step": 2190
    },
    {
      "epoch": 10.0,
      "grad_norm": 25.558629989624023,
      "learning_rate": 3.535353535353536e-08,
      "loss": 0.59,
      "step": 2200
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.6636363636363637,
      "eval_auc": 0.5354695579052833,
      "eval_f1": 0.1590909090909091,
      "eval_false_negatives": 251,
      "eval_false_positives": 45,
      "eval_loss": 0.6599389314651489,
      "eval_precision": 0.3835616438356164,
      "eval_recall/sensitivity": 0.1003584229390681,
      "eval_runtime": 15.5239,
      "eval_samples_per_second": 56.687,
      "eval_specificity": 0.9251247920133111,
      "eval_steps_per_second": 7.086,
      "eval_true_negatives": 556,
      "eval_true_positives": 28,
      "step": 2200
    }
  ],
  "logging_steps": 10,
  "max_steps": 2200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.097181183967232e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
